[package]
name = "llm-kit-groq"
version.workspace = true
edition.workspace = true
license.workspace = true
authors.workspace = true
repository.workspace = true
description = "Groq provider implementation for the AI SDK - supports chat and transcription models"
keywords = ["ai", "groq", "llm", "provider", "chat"]
categories = ["api-bindings", "asynchronous"]
readme = "README.md"

[dependencies]
llm-kit-provider = { path = "../llm-kit-provider", version = "0.1.0" }
llm-kit-provider-utils = { path = "../llm-kit-provider-utils", version = "0.1.0" }
llm-kit-openai-compatible = { path = "../llm-kit-openai-compatible", version = "0.1.0" }
tokio = { version = "1.41", features = ["full"] }
reqwest = { version = "0.12", features = ["json", "stream", "multipart"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2.0"
async-trait = "0.1"
futures-util = "0.3"
regex = "1.12"
chrono = "0.4"
base64 = "0.22"

[dev-dependencies]
tokio = { version = "1.41", features = ["macros", "rt-multi-thread"] }
